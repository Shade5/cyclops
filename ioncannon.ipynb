{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from IPython.display import SVG,display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 11\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hot(y):\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(11))\n",
    "    new_y = np.zeros((y.shape[0],y.shape[1]*num_classes))\n",
    "    for i in range(len(y)):\n",
    "        new_y[i,:] = label_binarizer.transform(y[i]).flatten()\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acccc(model):\n",
    "    A = np.array(model.predict(x_test))\n",
    "    c=0\n",
    "    for i in range(A.shape[1]):\n",
    "           c+=np.array_equal(np.argmax(np.array(A[:,i,:]),axis=1)[0:5],np.argmax(y_test[i].reshape((6,11)),axis=1)[0:5])\n",
    "    print(\"Accuracy:\",100*c/A.shape[1])\n",
    "    return 100*c/A.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = np.load(\"resizecrop.npy\")\n",
    "# Y = np.load(\"nummertrain.npy\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load(\"aug/resize_cropImage.npy\")\n",
    "Y = np.load(\"aug/nummertrain.npy\").astype(int)\n",
    "A3 = np.load(\"aug/resize_aug2t3ima.npy\")\n",
    "N3 = np.load(\"aug/aug2t3nummer.npy\").astype(int)\n",
    "A4 = np.load(\"aug/resize_aug3t4ima.npy\")\n",
    "N4 = np.load(\"aug/aug3t4nummer.npy\").astype(int)\n",
    "A5 = np.load(\"aug/resize_aug4t5ima.npy\")\n",
    "N5 = np.load(\"aug/aug4t5nummer.npy\").astype(int)\n",
    "X = np.vstack((X,A3,A4,A5))\n",
    "Y = np.vstack((Y,N3,N4,N5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = hot(Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (49325, 50, 50, 3)\n",
      "y_train shape: (49325, 11)\n",
      "49325 train samples\n"
     ]
    }
   ],
   "source": [
    "y1,y2,y3,y4,y5,ynum = y_train[:,0:11],y_train[:,11:22],y_train[:,22:33],y_train[:,33:44],y_train[:,44:55],y_train[:,55:66]\n",
    "y1_t,y2_t,y3_t,y4_t,y5_t,ynum_t = y_test[:,0:11],y_test[:,11:22],y_test[:,22:33],y_test[:,33:44],y_test[:,44:55],y_test[:,55:66]\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', ynum.shape)\n",
    "print(x_train.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "num = Dense(128, activation='relu')(conv_out)\n",
    "num = Dense(128, activation='relu')(num)\n",
    "num = Dropout(0.5)(num)\n",
    "numout = Dense(num_classes, activation='softmax',name=\"num\")(num)\n",
    "\n",
    "numtower = Model(inputs=inpu, outputs=numout)\n",
    "\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir='./logs/lay3', histogram_freq=0, write_graph=True, write_images=False))\n",
    "\n",
    "numtower.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49325 samples, validate on 12332 samples\n",
      "Epoch 1/15\n",
      "50s - loss: 0.7231 - acc: 0.7336 - val_loss: 0.3851 - val_acc: 0.8634\n",
      "Epoch 2/15\n",
      "47s - loss: 0.3008 - acc: 0.8992 - val_loss: 0.2488 - val_acc: 0.9153\n",
      "Epoch 3/15\n",
      "47s - loss: 0.2230 - acc: 0.9262 - val_loss: 0.1939 - val_acc: 0.9342\n",
      "Epoch 4/15\n",
      "47s - loss: 0.1834 - acc: 0.9394 - val_loss: 0.1957 - val_acc: 0.9357\n",
      "Epoch 5/15\n",
      "47s - loss: 0.1571 - acc: 0.9480 - val_loss: 0.2205 - val_acc: 0.9289\n",
      "Epoch 6/15\n",
      "47s - loss: 0.1359 - acc: 0.9552 - val_loss: 0.1892 - val_acc: 0.9389\n",
      "Epoch 7/15\n",
      "47s - loss: 0.1166 - acc: 0.9622 - val_loss: 0.1793 - val_acc: 0.9494\n",
      "Epoch 8/15\n",
      "47s - loss: 0.1045 - acc: 0.9658 - val_loss: 0.2367 - val_acc: 0.9402\n",
      "Epoch 9/15\n",
      "47s - loss: 0.0923 - acc: 0.9706 - val_loss: 0.1950 - val_acc: 0.9496\n",
      "Epoch 10/15\n",
      "47s - loss: 0.0839 - acc: 0.9726 - val_loss: 0.1885 - val_acc: 0.9536\n",
      "Validation loss: 0.188469915172\n",
      "Validation accuracy: 0.953616607201\n"
     ]
    }
   ],
   "source": [
    "numtower.fit(x_train, ynum,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        #validation_split=0.2,\n",
    "        validation_data=(x_test,ynum_t),\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = numtower.evaluate(x_test, ynum_t, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])\n",
    "\n",
    "numtower.save('ioncanonnum.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number tower complete\n",
      "\n",
      "starting Digit1\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Number tower complete\")\n",
    "print()\n",
    "\n",
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit1\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dropout(0.5)(x1)\n",
    "\n",
    "\n",
    "x1 = Dense(num_classes, activation='softmax', name='x2')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir='./logs/digit1/lay(2,2,4)', histogram_freq=0, write_graph=True, write_images=False))\n",
    "\n",
    "d1 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49325 samples, validate on 12332 samples\n",
      "Epoch 1/15\n",
      "96s - loss: 1.7065 - acc: 0.4285 - val_loss: 0.9186 - val_acc: 0.7132\n",
      "Epoch 2/15\n",
      "92s - loss: 0.7725 - acc: 0.7650 - val_loss: 0.5917 - val_acc: 0.8195\n",
      "Epoch 3/15\n",
      "91s - loss: 0.5518 - acc: 0.8356 - val_loss: 0.4979 - val_acc: 0.8524\n",
      "Epoch 4/15\n",
      "94s - loss: 0.4450 - acc: 0.8672 - val_loss: 0.4977 - val_acc: 0.8618\n",
      "Epoch 5/15\n",
      "90s - loss: 0.3812 - acc: 0.8866 - val_loss: 0.3859 - val_acc: 0.8871\n",
      "Epoch 6/15\n",
      "90s - loss: 0.3229 - acc: 0.9024 - val_loss: 0.4129 - val_acc: 0.8890\n",
      "Epoch 7/15\n",
      "89s - loss: 0.2878 - acc: 0.9124 - val_loss: 0.4329 - val_acc: 0.8778\n",
      "Epoch 8/15\n",
      "89s - loss: 0.2468 - acc: 0.9264 - val_loss: 0.3961 - val_acc: 0.8948\n",
      "Test loss: 0.39614939124\n",
      "Test accuracy: 0.894826467726\n"
     ]
    }
   ],
   "source": [
    "d1.fit(x_train,y1,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        #validation_split=0.2,\n",
    "        validation_data=(x_test,y1_t),\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d1.evaluate(x_test, y1_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d1.save('ioncanond1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Digit2\n"
     ]
    }
   ],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit2\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x3')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d2 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39460 samples, validate on 9865 samples\n",
      "Epoch 1/15\n",
      "73s - loss: 2.0206 - acc: 0.3031 - val_loss: 1.4877 - val_acc: 0.5332\n",
      "Epoch 2/15\n",
      "74s - loss: 1.1719 - acc: 0.6318 - val_loss: 0.8893 - val_acc: 0.7196\n",
      "Epoch 3/15\n",
      "72s - loss: 0.8435 - acc: 0.7421 - val_loss: 0.7257 - val_acc: 0.7814\n",
      "Epoch 4/15\n",
      "72s - loss: 0.6820 - acc: 0.7919 - val_loss: 0.6965 - val_acc: 0.7859\n",
      "Epoch 5/15\n",
      "73s - loss: 0.5777 - acc: 0.8284 - val_loss: 0.6139 - val_acc: 0.8097\n",
      "Epoch 6/15\n",
      "72s - loss: 0.4994 - acc: 0.8509 - val_loss: 0.5849 - val_acc: 0.8270\n",
      "Epoch 7/15\n",
      "75s - loss: 0.4262 - acc: 0.8715 - val_loss: 0.5858 - val_acc: 0.8269\n",
      "Epoch 8/15\n",
      "74s - loss: 0.3732 - acc: 0.8878 - val_loss: 0.6164 - val_acc: 0.8325\n",
      "Epoch 9/15\n",
      "78s - loss: 0.3310 - acc: 0.9000 - val_loss: 0.5944 - val_acc: 0.8348\n",
      "Test loss: 0.571872912857\n",
      "Test accuracy: 0.839604281544\n"
     ]
    }
   ],
   "source": [
    "d2.fit(x_train,y2,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d2.evaluate(x_test, y2_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d2.save('ioncanond2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Digit3\n"
     ]
    }
   ],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit3\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dropout(0.5)(x1)\n",
    "\n",
    "\n",
    "x1 = Dense(num_classes, activation='softmax', name='x1')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d3 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39460 samples, validate on 9865 samples\n",
      "Epoch 1/15\n",
      "76s - loss: 1.6044 - acc: 0.4719 - val_loss: 1.1730 - val_acc: 0.6576\n",
      "Epoch 2/15\n",
      "76s - loss: 1.0095 - acc: 0.6832 - val_loss: 0.7695 - val_acc: 0.7678\n",
      "Epoch 3/15\n",
      "76s - loss: 0.7804 - acc: 0.7615 - val_loss: 0.8018 - val_acc: 0.7556\n",
      "Epoch 4/15\n",
      "72s - loss: 0.6469 - acc: 0.8025 - val_loss: 0.6196 - val_acc: 0.8116\n",
      "Epoch 5/15\n",
      "73s - loss: 0.5521 - acc: 0.8341 - val_loss: 0.6104 - val_acc: 0.8124\n",
      "Epoch 6/15\n",
      "72s - loss: 0.4745 - acc: 0.8549 - val_loss: 0.5271 - val_acc: 0.8446\n",
      "Epoch 7/15\n",
      "72s - loss: 0.4171 - acc: 0.8760 - val_loss: 0.5016 - val_acc: 0.8541\n",
      "Epoch 8/15\n",
      "72s - loss: 0.3661 - acc: 0.8909 - val_loss: 0.4847 - val_acc: 0.8581\n",
      "Epoch 9/15\n",
      "72s - loss: 0.3270 - acc: 0.9007 - val_loss: 0.4956 - val_acc: 0.8547\n",
      "Epoch 10/15\n",
      "72s - loss: 0.2898 - acc: 0.9133 - val_loss: 0.5255 - val_acc: 0.8601\n",
      "Epoch 11/15\n",
      "72s - loss: 0.2515 - acc: 0.9245 - val_loss: 0.6021 - val_acc: 0.8631\n",
      "Test loss: 0.661282473662\n",
      "Test accuracy: 0.856389879987\n"
     ]
    }
   ],
   "source": [
    "d3.fit(x_train,y3,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d3.evaluate(x_test, y3_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d3.save('ioncanond3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Digit4\n"
     ]
    }
   ],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit4\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x4')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d4 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d4.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39460 samples, validate on 9865 samples\n",
      "Epoch 1/15\n",
      "75s - loss: 0.6718 - acc: 0.8195 - val_loss: 0.4792 - val_acc: 0.8335\n",
      "Epoch 2/15\n",
      "73s - loss: 0.4641 - acc: 0.8448 - val_loss: 0.5203 - val_acc: 0.8291\n",
      "Epoch 3/15\n",
      "73s - loss: 0.4048 - acc: 0.8709 - val_loss: 0.3714 - val_acc: 0.8833\n",
      "Epoch 4/15\n",
      "75s - loss: 0.3461 - acc: 0.8931 - val_loss: 0.4050 - val_acc: 0.8871\n",
      "Epoch 5/15\n",
      "76s - loss: 0.3049 - acc: 0.9092 - val_loss: 0.3267 - val_acc: 0.9064\n",
      "Epoch 6/15\n",
      "73s - loss: 0.2766 - acc: 0.9193 - val_loss: 0.2935 - val_acc: 0.9176\n",
      "Epoch 7/15\n",
      "73s - loss: 0.2524 - acc: 0.9256 - val_loss: 0.2899 - val_acc: 0.9211\n",
      "Epoch 8/15\n",
      "73s - loss: 0.2338 - acc: 0.9330 - val_loss: 0.2767 - val_acc: 0.9234\n",
      "Epoch 9/15\n",
      "74s - loss: 0.2082 - acc: 0.9392 - val_loss: 0.3035 - val_acc: 0.9165\n",
      "Epoch 10/15\n",
      "73s - loss: 0.1943 - acc: 0.9438 - val_loss: 0.2668 - val_acc: 0.9259\n",
      "Epoch 11/15\n",
      "73s - loss: 0.1814 - acc: 0.9483 - val_loss: 0.2699 - val_acc: 0.9277\n",
      "Epoch 12/15\n",
      "72s - loss: 0.1644 - acc: 0.9518 - val_loss: 0.2999 - val_acc: 0.9205\n",
      "Epoch 13/15\n",
      "72s - loss: 0.1503 - acc: 0.9568 - val_loss: 0.3273 - val_acc: 0.9251\n",
      "Test loss: 0.375217253899\n",
      "Test accuracy: 0.924262082407\n"
     ]
    }
   ],
   "source": [
    "d4.fit(x_train,y4,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d4.evaluate(x_test, y4_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11123 samples, validate on 2781 samples\n",
      "Epoch 1/20\n",
      "21s - loss: 1.8937 - acc: 0.4870 - val_loss: 1.5487 - val_acc: 0.5102\n",
      "Epoch 2/20\n",
      "20s - loss: 1.5297 - acc: 0.5218 - val_loss: 1.3914 - val_acc: 0.5588\n",
      "Epoch 3/20\n",
      "20s - loss: 1.3667 - acc: 0.5712 - val_loss: 1.3183 - val_acc: 0.5671\n",
      "Epoch 4/20\n",
      "20s - loss: 1.1909 - acc: 0.6237 - val_loss: 1.1056 - val_acc: 0.6490\n",
      "Epoch 5/20\n",
      "20s - loss: 1.0290 - acc: 0.6772 - val_loss: 0.9460 - val_acc: 0.7123\n",
      "Epoch 6/20\n",
      "20s - loss: 0.8702 - acc: 0.7254 - val_loss: 0.8336 - val_acc: 0.7443\n",
      "Epoch 7/20\n",
      "21s - loss: 0.7560 - acc: 0.7622 - val_loss: 0.7517 - val_acc: 0.7792\n",
      "Epoch 8/20\n",
      "20s - loss: 0.6557 - acc: 0.7913 - val_loss: 0.7713 - val_acc: 0.7659\n",
      "Epoch 9/20\n",
      "20s - loss: 0.5749 - acc: 0.8184 - val_loss: 0.7798 - val_acc: 0.7792\n",
      "Epoch 10/20\n",
      "20s - loss: 0.4914 - acc: 0.8443 - val_loss: 0.7683 - val_acc: 0.7709\n",
      "Epoch 11/20\n",
      "20s - loss: 0.4371 - acc: 0.8645 - val_loss: 0.7162 - val_acc: 0.8015\n",
      "Epoch 12/20\n",
      "20s - loss: 0.3918 - acc: 0.8790 - val_loss: 0.7078 - val_acc: 0.8170\n",
      "Epoch 13/20\n",
      "20s - loss: 0.3283 - acc: 0.8987 - val_loss: 0.7439 - val_acc: 0.8101\n",
      "Epoch 14/20\n",
      "20s - loss: 0.2940 - acc: 0.9078 - val_loss: 0.7287 - val_acc: 0.8166\n",
      "Epoch 15/20\n",
      "20s - loss: 0.2515 - acc: 0.9215 - val_loss: 0.7842 - val_acc: 0.8220\n",
      "Epoch 16/20\n",
      "21s - loss: 0.2106 - acc: 0.9299 - val_loss: 0.9876 - val_acc: 0.7878\n",
      "Epoch 17/20\n",
      "20s - loss: 0.1958 - acc: 0.9363 - val_loss: 0.8895 - val_acc: 0.8141\n",
      "Epoch 18/20\n",
      "20s - loss: 0.1697 - acc: 0.9476 - val_loss: 0.8499 - val_acc: 0.8234\n",
      "Test loss: 0.852179920646\n",
      "Test accuracy: 0.826237053948\n"
     ]
    }
   ],
   "source": [
    "print(\"part2\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=0)] \n",
    "\n",
    "X444 = np.load(\"aug/resize_aug3t4ima.npy\")\n",
    "y444 = np.load(\"aug/aug3t4nummer.npy\").astype(int)\n",
    "\n",
    "A3 = np.load(\"aug/resize_aug2t3ima.npy\")[0:8690]\n",
    "N3 = np.load(\"aug/aug2t3nummer.npy\").astype(int)[0:8690]\n",
    "\n",
    "X444 = np.vstack((X444,A3))\n",
    "y444 = np.vstack((y444,N3))\n",
    "\n",
    "y444 = hot(y444)\n",
    "x_train444, x_test444, y_train444, y_test444 = train_test_split(\n",
    "    X444, y444, test_size=0.2)\n",
    "y444 = y_train444[:,33:44]\n",
    "y444_t= y_test444[:,33:44]\n",
    "\n",
    "d4.fit(x_train444,y444,\n",
    "        batch_size=batch_size,\n",
    "        epochs=30,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d4.evaluate(x_test444, y444_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d4.save('ioncanond4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Digit5\n"
     ]
    }
   ],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit5\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x5')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d5 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d5.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39460 samples, validate on 9865 samples\n",
      "Epoch 1/15\n",
      "76s - loss: 0.2112 - acc: 0.9743 - val_loss: 0.1558 - val_acc: 0.9766\n",
      "Epoch 2/15\n",
      "72s - loss: 0.1158 - acc: 0.9768 - val_loss: 0.1011 - val_acc: 0.9766\n",
      "Epoch 3/15\n",
      "72s - loss: 0.0956 - acc: 0.9768 - val_loss: 0.0955 - val_acc: 0.9766\n",
      "Epoch 4/15\n",
      "73s - loss: 0.0935 - acc: 0.9767 - val_loss: 0.0875 - val_acc: 0.9766\n",
      "Epoch 5/15\n",
      "72s - loss: 0.0882 - acc: 0.9771 - val_loss: 0.0897 - val_acc: 0.9775\n",
      "Epoch 6/15\n",
      "72s - loss: 0.0885 - acc: 0.9775 - val_loss: 0.0851 - val_acc: 0.9774\n",
      "Epoch 7/15\n",
      "74s - loss: 0.0879 - acc: 0.9780 - val_loss: 0.1081 - val_acc: 0.9770\n",
      "Epoch 8/15\n",
      "72s - loss: 0.0806 - acc: 0.9778 - val_loss: 0.0841 - val_acc: 0.9779\n",
      "Epoch 9/15\n",
      "72s - loss: 0.0825 - acc: 0.9777 - val_loss: 0.0778 - val_acc: 0.9784\n",
      "Epoch 10/15\n",
      "72s - loss: 0.0829 - acc: 0.9780 - val_loss: 0.0862 - val_acc: 0.9777\n",
      "Epoch 11/15\n",
      "72s - loss: 0.0831 - acc: 0.9781 - val_loss: 0.0924 - val_acc: 0.9779\n",
      "Epoch 12/15\n",
      "72s - loss: 0.0814 - acc: 0.9781 - val_loss: 0.0981 - val_acc: 0.9769\n",
      "Test loss: 0.109436033977\n",
      "Test accuracy: 0.976078495011\n"
     ]
    }
   ],
   "source": [
    "d5.fit(x_train,y5,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d5.evaluate(x_test, y5_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1877 samples, validate on 470 samples\n",
      "Epoch 1/40\n",
      "3s - loss: 2.4404 - acc: 0.3900 - val_loss: 1.7098 - val_acc: 0.5596\n",
      "Epoch 2/40\n",
      "3s - loss: 1.9219 - acc: 0.4795 - val_loss: 1.7046 - val_acc: 0.5596\n",
      "Epoch 3/40\n",
      "3s - loss: 1.8436 - acc: 0.4907 - val_loss: 1.6705 - val_acc: 0.5596\n",
      "Epoch 4/40\n",
      "3s - loss: 1.7823 - acc: 0.4928 - val_loss: 1.5902 - val_acc: 0.5596\n",
      "Epoch 5/40\n",
      "3s - loss: 1.7339 - acc: 0.4944 - val_loss: 1.4598 - val_acc: 0.5596\n",
      "Epoch 6/40\n",
      "3s - loss: 1.6331 - acc: 0.4997 - val_loss: 1.3696 - val_acc: 0.5660\n",
      "Epoch 7/40\n",
      "3s - loss: 1.4986 - acc: 0.5152 - val_loss: 1.3758 - val_acc: 0.5723\n",
      "Epoch 8/40\n",
      "3s - loss: 1.4033 - acc: 0.5344 - val_loss: 1.2217 - val_acc: 0.5915\n",
      "Epoch 9/40\n",
      "3s - loss: 1.3422 - acc: 0.5424 - val_loss: 1.1748 - val_acc: 0.6064\n",
      "Epoch 10/40\n",
      "3s - loss: 1.2940 - acc: 0.5509 - val_loss: 1.1431 - val_acc: 0.6085\n",
      "Epoch 11/40\n",
      "3s - loss: 1.2570 - acc: 0.5621 - val_loss: 1.1494 - val_acc: 0.6128\n",
      "Epoch 12/40\n",
      "3s - loss: 1.2428 - acc: 0.5503 - val_loss: 1.1115 - val_acc: 0.6340\n",
      "Epoch 13/40\n",
      "3s - loss: 1.2031 - acc: 0.5759 - val_loss: 1.2136 - val_acc: 0.6106\n",
      "Epoch 14/40\n",
      "3s - loss: 1.1926 - acc: 0.5738 - val_loss: 1.0999 - val_acc: 0.6362\n",
      "Epoch 15/40\n",
      "3s - loss: 1.1719 - acc: 0.5807 - val_loss: 1.1773 - val_acc: 0.5936\n",
      "Epoch 16/40\n",
      "3s - loss: 1.1617 - acc: 0.5823 - val_loss: 1.1259 - val_acc: 0.6277\n",
      "Epoch 17/40\n",
      "3s - loss: 1.1366 - acc: 0.5951 - val_loss: 1.1594 - val_acc: 0.6064\n",
      "Epoch 18/40\n",
      "3s - loss: 1.1166 - acc: 0.6079 - val_loss: 1.1183 - val_acc: 0.6340\n",
      "Epoch 19/40\n",
      "3s - loss: 1.0957 - acc: 0.6100 - val_loss: 1.0932 - val_acc: 0.6191\n",
      "Epoch 20/40\n",
      "3s - loss: 1.0331 - acc: 0.6361 - val_loss: 1.1279 - val_acc: 0.6362\n",
      "Epoch 21/40\n",
      "3s - loss: 1.0113 - acc: 0.6569 - val_loss: 1.0789 - val_acc: 0.6596\n",
      "Epoch 22/40\n",
      "3s - loss: 0.9496 - acc: 0.6766 - val_loss: 1.0973 - val_acc: 0.6553\n",
      "Epoch 23/40\n",
      "3s - loss: 0.9104 - acc: 0.6899 - val_loss: 1.1481 - val_acc: 0.6660\n",
      "Epoch 24/40\n",
      "3s - loss: 0.8606 - acc: 0.7086 - val_loss: 1.0877 - val_acc: 0.6638\n",
      "Epoch 25/40\n",
      "3s - loss: 0.8021 - acc: 0.7283 - val_loss: 1.1142 - val_acc: 0.6745\n",
      "Epoch 26/40\n",
      "3s - loss: 0.7889 - acc: 0.7464 - val_loss: 1.0881 - val_acc: 0.6872\n",
      "Epoch 27/40\n",
      "3s - loss: 0.6988 - acc: 0.7730 - val_loss: 1.1252 - val_acc: 0.6851\n",
      "Test loss: 1.27312235207\n",
      "Test accuracy: 0.632027257646\n"
     ]
    }
   ],
   "source": [
    "print(\"part2\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=0)] \n",
    "\n",
    "X555 = np.load(\"aug/resize_aug4t5ima.npy\")\n",
    "y555 = np.load(\"aug/aug4t5nummer.npy\").astype(int)\n",
    "\n",
    "A4 = np.load(\"aug/resize_aug3t4ima.npy\")[0:1500]\n",
    "N4 = np.load(\"aug/aug3t4nummer.npy\").astype(int)[0:1500]\n",
    "\n",
    "X555 = np.vstack((X555,A4))\n",
    "y555 = np.vstack((y555,N4))\n",
    "\n",
    "y555 = hot(y555)\n",
    "x_train555, x_test555, y_train555, y_test555 = train_test_split(\n",
    "    X555, y555, test_size=0.2)\n",
    "y555 = y_train555[:,44:55]\n",
    "y555_t= y_test555[:,44:55]\n",
    "\n",
    "d5.fit(x_train555,y555,\n",
    "        batch_size=batch_size,\n",
    "        epochs=40,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d5.evaluate(x_test555, y555_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d5.save('ioncanond5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGING!!\n"
     ]
    }
   ],
   "source": [
    "print(\"MERGING!!\")\n",
    "\n",
    "import h5py\n",
    "# f = h5py.File('ioncanond1.h5', 'r+')\n",
    "# del f['optimizer_weights']\n",
    "# f.close()\n",
    "      \n",
    "digit1 = load_model('ioncanond1.h5')\n",
    "digit1.name =\"digit1\"\n",
    "\n",
    "digit2 = load_model('ioncanond2.h5')\n",
    "digit2.name =\"digit2\"\n",
    "\n",
    "digit3 = load_model('ioncanond3.h5')\n",
    "digit3.name =\"digit3\"\n",
    "\n",
    "digit4 = load_model('ioncanond4.h5')\n",
    "digit4.name =\"digit4\"\n",
    "\n",
    "digit5 = load_model('ioncanond5.h5')\n",
    "digit5.name =\"digit5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Merging\n",
    "d1 = digit1(a)\n",
    "\n",
    "d2 = digit2(a)\n",
    "\n",
    "d3 = digit3(a)\n",
    "\n",
    "d4 = digit4(a)\n",
    "\n",
    "d5 = digit5(a)\n",
    "\n",
    "model = Model(inputs=a, outputs=[d1, d2, d3, d4, d5])\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.298410638987995\n",
      "Initial accuracy:  60.298410638987995\n"
     ]
    }
   ],
   "source": [
    "acc = acccc(model)\n",
    "print(\"Initial accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49325 samples, validate on 12332 samples\n",
      "Epoch 1/1\n",
      "460s - loss: 1.4733 - digit1_loss: 0.2767 - digit2_loss: 0.4165 - digit3_loss: 0.3769 - digit4_loss: 0.3240 - digit5_loss: 0.0792 - digit1_acc: 0.9210 - digit2_acc: 0.8802 - digit3_acc: 0.8944 - digit4_acc: 0.9156 - digit5_acc: 0.9803 - val_loss: 1.3447 - val_digit1_loss: 0.2514 - val_digit2_loss: 0.4046 - val_digit3_loss: 0.3294 - val_digit4_loss: 0.2759 - val_digit5_loss: 0.0834 - val_digit1_acc: 0.9224 - val_digit2_acc: 0.8791 - val_digit3_acc: 0.9105 - val_digit4_acc: 0.9256 - val_digit5_acc: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd002a23c50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(x_train,[y1,y2,y3,y4,y5],\n",
    "#             batch_size=batch_size,\n",
    "#             epochs=1,\n",
    "#             #validation_split=0.2,\n",
    "#             validation_data=(x_test,[y1_t,y2_t,y3_t,y4_t,y5_t]),\n",
    "#             shuffle=True,\n",
    "#             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(\"ioncannonaug.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
