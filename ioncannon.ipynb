{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from IPython.display import SVG,display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 11\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hot(y):\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(11))\n",
    "    new_y = np.zeros((y.shape[0],y.shape[1]*num_classes))\n",
    "    for i in range(len(y)):\n",
    "        new_y[i,:] = label_binarizer.transform(y[i]).flatten()\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acccc(model):\n",
    "    A = np.array(model.predict(x_test))\n",
    "    c=0\n",
    "    for i in range(A.shape[1]):\n",
    "           c+=np.array_equal(np.argmax(np.array(A[:,i,:]),axis=1)[0:5],np.argmax(y_test[i].reshape((6,11)),axis=1)[0:5])\n",
    "    print(\"Accuracy:\",100*c/A.shape[1])\n",
    "    return 100*c/A.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = np.load(\"resizecrop.npy\")\n",
    "# Y = np.load(\"nummertrain.npy\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load(\"aug/resize_cropImage.npy\")\n",
    "Y = np.load(\"aug/nummertrain.npy\").astype(int)\n",
    "A3 = np.load(\"aug/resize_aug2t3ima.npy\")\n",
    "N3 = np.load(\"aug/aug2t3nummer.npy\").astype(int)\n",
    "A4 = np.load(\"aug/resize_aug3t4ima.npy\")\n",
    "N4 = np.load(\"aug/aug3t4nummer.npy\").astype(int)\n",
    "A5 = np.load(\"aug/resize_aug4t5ima.npy\")\n",
    "N5 = np.load(\"aug/aug4t5nummer.npy\").astype(int)\n",
    "X = np.vstack((X,A3,A4,A5))\n",
    "Y = np.vstack((Y,N3,N4,N5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = hot(Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (49325, 50, 50, 3)\n",
      "y_train shape: (49325, 11)\n",
      "49325 train samples\n"
     ]
    }
   ],
   "source": [
    "y1,y2,y3,y4,y5,ynum = y_train[:,0:11],y_train[:,11:22],y_train[:,22:33],y_train[:,33:44],y_train[:,44:55],y_train[:,55:66]\n",
    "y1_t,y2_t,y3_t,y4_t,y5_t,ynum_t = y_test[:,0:11],y_test[:,11:22],y_test[:,22:33],y_test[:,33:44],y_test[:,44:55],y_test[:,55:66]\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', ynum.shape)\n",
    "print(x_train.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "num = Dense(128, activation='relu')(conv_out)\n",
    "num = Dense(128, activation='relu')(num)\n",
    "num = Dropout(0.5)(num)\n",
    "numout = Dense(num_classes, activation='softmax',name=\"num\")(num)\n",
    "\n",
    "numtower = Model(inputs=inpu, outputs=numout)\n",
    "\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir='./logs/lay3', histogram_freq=0, write_graph=True, write_images=False))\n",
    "\n",
    "numtower.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49325 samples, validate on 12332 samples\n",
      "Epoch 1/15\n",
      "50s - loss: 0.7231 - acc: 0.7336 - val_loss: 0.3851 - val_acc: 0.8634\n",
      "Epoch 2/15\n",
      "47s - loss: 0.3008 - acc: 0.8992 - val_loss: 0.2488 - val_acc: 0.9153\n",
      "Epoch 3/15\n",
      "47s - loss: 0.2230 - acc: 0.9262 - val_loss: 0.1939 - val_acc: 0.9342\n",
      "Epoch 4/15\n",
      "47s - loss: 0.1834 - acc: 0.9394 - val_loss: 0.1957 - val_acc: 0.9357\n",
      "Epoch 5/15\n",
      "47s - loss: 0.1571 - acc: 0.9480 - val_loss: 0.2205 - val_acc: 0.9289\n",
      "Epoch 6/15\n",
      "47s - loss: 0.1359 - acc: 0.9552 - val_loss: 0.1892 - val_acc: 0.9389\n",
      "Epoch 7/15\n",
      "47s - loss: 0.1166 - acc: 0.9622 - val_loss: 0.1793 - val_acc: 0.9494\n",
      "Epoch 8/15\n",
      "47s - loss: 0.1045 - acc: 0.9658 - val_loss: 0.2367 - val_acc: 0.9402\n",
      "Epoch 9/15\n",
      "47s - loss: 0.0923 - acc: 0.9706 - val_loss: 0.1950 - val_acc: 0.9496\n",
      "Epoch 10/15\n",
      "47s - loss: 0.0839 - acc: 0.9726 - val_loss: 0.1885 - val_acc: 0.9536\n",
      "Validation loss: 0.188469915172\n",
      "Validation accuracy: 0.953616607201\n"
     ]
    }
   ],
   "source": [
    "numtower.fit(x_train, ynum,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        #validation_split=0.2,\n",
    "        validation_data=(x_test,ynum_t),\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = numtower.evaluate(x_test, ynum_t, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])\n",
    "\n",
    "numtower.save('ioncanonnum.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number tower complete\n",
      "\n",
      "starting Digit1\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Number tower complete\")\n",
    "print()\n",
    "\n",
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit1\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dropout(0.5)(x1)\n",
    "\n",
    "\n",
    "x1 = Dense(num_classes, activation='softmax', name='x2')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir='./logs/digit1/lay(2,2,4)', histogram_freq=0, write_graph=True, write_images=False))\n",
    "\n",
    "d1 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49325 samples, validate on 12332 samples\n",
      "Epoch 1/15\n",
      "96s - loss: 1.7065 - acc: 0.4285 - val_loss: 0.9186 - val_acc: 0.7132\n",
      "Epoch 2/15\n",
      "92s - loss: 0.7725 - acc: 0.7650 - val_loss: 0.5917 - val_acc: 0.8195\n",
      "Epoch 3/15\n",
      "91s - loss: 0.5518 - acc: 0.8356 - val_loss: 0.4979 - val_acc: 0.8524\n",
      "Epoch 4/15\n",
      "94s - loss: 0.4450 - acc: 0.8672 - val_loss: 0.4977 - val_acc: 0.8618\n",
      "Epoch 5/15\n",
      "90s - loss: 0.3812 - acc: 0.8866 - val_loss: 0.3859 - val_acc: 0.8871\n",
      "Epoch 6/15\n",
      "90s - loss: 0.3229 - acc: 0.9024 - val_loss: 0.4129 - val_acc: 0.8890\n",
      "Epoch 7/15\n",
      "89s - loss: 0.2878 - acc: 0.9124 - val_loss: 0.4329 - val_acc: 0.8778\n",
      "Epoch 8/15\n",
      "89s - loss: 0.2468 - acc: 0.9264 - val_loss: 0.3961 - val_acc: 0.8948\n",
      "Test loss: 0.39614939124\n",
      "Test accuracy: 0.894826467726\n"
     ]
    }
   ],
   "source": [
    "d1.fit(x_train,y1,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        #validation_split=0.2,\n",
    "        validation_data=(x_test,y1_t),\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d1.evaluate(x_test, y1_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d1.save('ioncanond1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Digit2\n"
     ]
    }
   ],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit2\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x3')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d2 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39460 samples, validate on 9865 samples\n",
      "Epoch 1/15\n",
      "73s - loss: 2.0206 - acc: 0.3031 - val_loss: 1.4877 - val_acc: 0.5332\n",
      "Epoch 2/15\n",
      "74s - loss: 1.1719 - acc: 0.6318 - val_loss: 0.8893 - val_acc: 0.7196\n",
      "Epoch 3/15\n",
      "72s - loss: 0.8435 - acc: 0.7421 - val_loss: 0.7257 - val_acc: 0.7814\n",
      "Epoch 4/15\n",
      "72s - loss: 0.6820 - acc: 0.7919 - val_loss: 0.6965 - val_acc: 0.7859\n",
      "Epoch 5/15\n",
      "73s - loss: 0.5777 - acc: 0.8284 - val_loss: 0.6139 - val_acc: 0.8097\n",
      "Epoch 6/15\n",
      "72s - loss: 0.4994 - acc: 0.8509 - val_loss: 0.5849 - val_acc: 0.8270\n",
      "Epoch 7/15\n",
      "75s - loss: 0.4262 - acc: 0.8715 - val_loss: 0.5858 - val_acc: 0.8269\n",
      "Epoch 8/15\n",
      "74s - loss: 0.3732 - acc: 0.8878 - val_loss: 0.6164 - val_acc: 0.8325\n",
      "Epoch 9/15\n",
      "78s - loss: 0.3310 - acc: 0.9000 - val_loss: 0.5944 - val_acc: 0.8348\n",
      "Test loss: 0.571872912857\n",
      "Test accuracy: 0.839604281544\n"
     ]
    }
   ],
   "source": [
    "d2.fit(x_train,y2,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d2.evaluate(x_test, y2_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d2.save('ioncanond2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Digit3\n"
     ]
    }
   ],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit3\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dropout(0.5)(x1)\n",
    "\n",
    "\n",
    "x1 = Dense(num_classes, activation='softmax', name='x1')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d3 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39460 samples, validate on 9865 samples\n",
      "Epoch 1/15\n",
      "76s - loss: 1.6044 - acc: 0.4719 - val_loss: 1.1730 - val_acc: 0.6576\n",
      "Epoch 2/15\n",
      "76s - loss: 1.0095 - acc: 0.6832 - val_loss: 0.7695 - val_acc: 0.7678\n",
      "Epoch 3/15\n",
      "76s - loss: 0.7804 - acc: 0.7615 - val_loss: 0.8018 - val_acc: 0.7556\n",
      "Epoch 4/15\n",
      "72s - loss: 0.6469 - acc: 0.8025 - val_loss: 0.6196 - val_acc: 0.8116\n",
      "Epoch 5/15\n",
      "73s - loss: 0.5521 - acc: 0.8341 - val_loss: 0.6104 - val_acc: 0.8124\n",
      "Epoch 6/15\n",
      "72s - loss: 0.4745 - acc: 0.8549 - val_loss: 0.5271 - val_acc: 0.8446\n",
      "Epoch 7/15\n",
      "72s - loss: 0.4171 - acc: 0.8760 - val_loss: 0.5016 - val_acc: 0.8541\n",
      "Epoch 8/15\n",
      "72s - loss: 0.3661 - acc: 0.8909 - val_loss: 0.4847 - val_acc: 0.8581\n",
      "Epoch 9/15\n",
      "72s - loss: 0.3270 - acc: 0.9007 - val_loss: 0.4956 - val_acc: 0.8547\n",
      "Epoch 10/15\n",
      "72s - loss: 0.2898 - acc: 0.9133 - val_loss: 0.5255 - val_acc: 0.8601\n",
      "Epoch 11/15\n",
      "72s - loss: 0.2515 - acc: 0.9245 - val_loss: 0.6021 - val_acc: 0.8631\n",
      "Test loss: 0.661282473662\n",
      "Test accuracy: 0.856389879987\n"
     ]
    }
   ],
   "source": [
    "d3.fit(x_train,y3,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d3.evaluate(x_test, y3_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d3.save('ioncanond3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Digit4\n"
     ]
    }
   ],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit4\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x4')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d4 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d4.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39460 samples, validate on 9865 samples\n",
      "Epoch 1/15\n",
      "75s - loss: 0.6718 - acc: 0.8195 - val_loss: 0.4792 - val_acc: 0.8335\n",
      "Epoch 2/15\n",
      "73s - loss: 0.4641 - acc: 0.8448 - val_loss: 0.5203 - val_acc: 0.8291\n",
      "Epoch 3/15\n",
      "73s - loss: 0.4048 - acc: 0.8709 - val_loss: 0.3714 - val_acc: 0.8833\n",
      "Epoch 4/15\n",
      "75s - loss: 0.3461 - acc: 0.8931 - val_loss: 0.4050 - val_acc: 0.8871\n",
      "Epoch 5/15\n",
      "76s - loss: 0.3049 - acc: 0.9092 - val_loss: 0.3267 - val_acc: 0.9064\n",
      "Epoch 6/15\n",
      "73s - loss: 0.2766 - acc: 0.9193 - val_loss: 0.2935 - val_acc: 0.9176\n",
      "Epoch 7/15\n",
      "73s - loss: 0.2524 - acc: 0.9256 - val_loss: 0.2899 - val_acc: 0.9211\n",
      "Epoch 8/15\n",
      "73s - loss: 0.2338 - acc: 0.9330 - val_loss: 0.2767 - val_acc: 0.9234\n",
      "Epoch 9/15\n",
      "74s - loss: 0.2082 - acc: 0.9392 - val_loss: 0.3035 - val_acc: 0.9165\n",
      "Epoch 10/15\n",
      "73s - loss: 0.1943 - acc: 0.9438 - val_loss: 0.2668 - val_acc: 0.9259\n",
      "Epoch 11/15\n",
      "73s - loss: 0.1814 - acc: 0.9483 - val_loss: 0.2699 - val_acc: 0.9277\n",
      "Epoch 12/15\n",
      "72s - loss: 0.1644 - acc: 0.9518 - val_loss: 0.2999 - val_acc: 0.9205\n",
      "Epoch 13/15\n",
      "72s - loss: 0.1503 - acc: 0.9568 - val_loss: 0.3273 - val_acc: 0.9251\n",
      "Test loss: 0.375217253899\n",
      "Test accuracy: 0.924262082407\n"
     ]
    }
   ],
   "source": [
    "d4.fit(x_train,y4,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d4.evaluate(x_test, y4_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part2\n",
      "Train on 5561 samples, validate on 1391 samples\n",
      "Epoch 1/50\n",
      "10s - loss: 0.5948 - acc: 0.8335 - val_loss: 0.4704 - val_acc: 0.8577\n",
      "Epoch 2/50\n",
      "10s - loss: 0.4298 - acc: 0.8669 - val_loss: 0.4641 - val_acc: 0.8713\n",
      "Epoch 3/50\n",
      "10s - loss: 0.3448 - acc: 0.8937 - val_loss: 0.4697 - val_acc: 0.8670\n",
      "Epoch 4/50\n",
      "10s - loss: 0.2658 - acc: 0.9176 - val_loss: 0.5950 - val_acc: 0.8533\n",
      "Epoch 5/50\n",
      "10s - loss: 0.2107 - acc: 0.9351 - val_loss: 0.5153 - val_acc: 0.8627\n",
      "Epoch 6/50\n",
      "10s - loss: 0.1548 - acc: 0.9471 - val_loss: 0.6252 - val_acc: 0.8569\n",
      "Epoch 7/50\n",
      "10s - loss: 0.1394 - acc: 0.9552 - val_loss: 0.6212 - val_acc: 0.8613\n",
      "Epoch 8/50\n",
      "10s - loss: 0.1169 - acc: 0.9658 - val_loss: 0.6370 - val_acc: 0.8548\n",
      "Test loss: 0.63658831141\n",
      "Test accuracy: 0.864787111623\n"
     ]
    }
   ],
   "source": [
    "print(\"part2\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=0)] \n",
    "\n",
    "X444 = np.load(\"aug/resize_aug3t4ima.npy\")\n",
    "y444 = np.load(\"aug/aug3t4nummer.npy\").astype(int)\n",
    "\n",
    "y444 = hot(y444)\n",
    "x_train444, x_test444, y_train444, y_test444 = train_test_split(\n",
    "    X444, y444, test_size=0.2)\n",
    "y444 = y_train444[:,33:44]\n",
    "y444_t= y_test444[:,33:44]\n",
    "\n",
    "d4.fit(x_train444,y444,\n",
    "        batch_size=batch_size,\n",
    "        epochs=20,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d4.evaluate(x_test444, y444_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d4.save('ioncanond4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Digit5\n"
     ]
    }
   ],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit5\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x5')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d5 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d5.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39460 samples, validate on 9865 samples\n",
      "Epoch 1/15\n",
      "76s - loss: 0.2112 - acc: 0.9743 - val_loss: 0.1558 - val_acc: 0.9766\n",
      "Epoch 2/15\n",
      "72s - loss: 0.1158 - acc: 0.9768 - val_loss: 0.1011 - val_acc: 0.9766\n",
      "Epoch 3/15\n",
      "72s - loss: 0.0956 - acc: 0.9768 - val_loss: 0.0955 - val_acc: 0.9766\n",
      "Epoch 4/15\n",
      "73s - loss: 0.0935 - acc: 0.9767 - val_loss: 0.0875 - val_acc: 0.9766\n",
      "Epoch 5/15\n",
      "72s - loss: 0.0882 - acc: 0.9771 - val_loss: 0.0897 - val_acc: 0.9775\n",
      "Epoch 6/15\n",
      "72s - loss: 0.0885 - acc: 0.9775 - val_loss: 0.0851 - val_acc: 0.9774\n",
      "Epoch 7/15\n",
      "74s - loss: 0.0879 - acc: 0.9780 - val_loss: 0.1081 - val_acc: 0.9770\n",
      "Epoch 8/15\n",
      "72s - loss: 0.0806 - acc: 0.9778 - val_loss: 0.0841 - val_acc: 0.9779\n",
      "Epoch 9/15\n",
      "72s - loss: 0.0825 - acc: 0.9777 - val_loss: 0.0778 - val_acc: 0.9784\n",
      "Epoch 10/15\n",
      "72s - loss: 0.0829 - acc: 0.9780 - val_loss: 0.0862 - val_acc: 0.9777\n",
      "Epoch 11/15\n",
      "72s - loss: 0.0831 - acc: 0.9781 - val_loss: 0.0924 - val_acc: 0.9779\n",
      "Epoch 12/15\n",
      "72s - loss: 0.0814 - acc: 0.9781 - val_loss: 0.0981 - val_acc: 0.9769\n",
      "Test loss: 0.109436033977\n",
      "Test accuracy: 0.976078495011\n"
     ]
    }
   ],
   "source": [
    "d5.fit(x_train,y5,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d5.evaluate(x_test, y5_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part2\n",
      "Train on 917 samples, validate on 230 samples\n",
      "Epoch 1/20\n",
      "1s - loss: 1.7649 - acc: 0.3904 - val_loss: 1.6645 - val_acc: 0.4130\n",
      "Epoch 2/20\n",
      "1s - loss: 1.6872 - acc: 0.4100 - val_loss: 1.5602 - val_acc: 0.4522\n",
      "Epoch 3/20\n",
      "1s - loss: 1.6247 - acc: 0.4242 - val_loss: 1.5607 - val_acc: 0.4609\n",
      "Epoch 4/20\n",
      "1s - loss: 1.6415 - acc: 0.4297 - val_loss: 1.5005 - val_acc: 0.4870\n",
      "Epoch 5/20\n",
      "1s - loss: 1.5642 - acc: 0.4711 - val_loss: 1.4765 - val_acc: 0.4826\n",
      "Epoch 6/20\n",
      "1s - loss: 1.4838 - acc: 0.4820 - val_loss: 1.4540 - val_acc: 0.4696\n",
      "Epoch 7/20\n",
      "1s - loss: 1.4445 - acc: 0.5038 - val_loss: 1.5256 - val_acc: 0.4957\n",
      "Epoch 8/20\n",
      "1s - loss: 1.4049 - acc: 0.5289 - val_loss: 1.5805 - val_acc: 0.4478\n",
      "Epoch 9/20\n",
      "1s - loss: 1.4149 - acc: 0.5191 - val_loss: 1.4147 - val_acc: 0.4870\n",
      "Epoch 10/20\n",
      "1s - loss: 1.2898 - acc: 0.5453 - val_loss: 1.4820 - val_acc: 0.4696\n",
      "Epoch 11/20\n",
      "1s - loss: 1.3132 - acc: 0.5551 - val_loss: 1.4641 - val_acc: 0.4783\n",
      "Epoch 12/20\n",
      "1s - loss: 1.2176 - acc: 0.5769 - val_loss: 1.4916 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "1s - loss: 1.1385 - acc: 0.6129 - val_loss: 1.4692 - val_acc: 0.5000\n",
      "Epoch 14/20\n",
      "1s - loss: 1.1110 - acc: 0.6096 - val_loss: 1.5851 - val_acc: 0.4696\n",
      "Epoch 15/20\n",
      "1s - loss: 1.0545 - acc: 0.6205 - val_loss: 1.4556 - val_acc: 0.4913\n",
      "Test loss: 1.51740147635\n",
      "Test accuracy: 0.540069684542\n"
     ]
    }
   ],
   "source": [
    "print(\"part2\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=0)] \n",
    "\n",
    "X555 = np.load(\"aug/resize_aug4t5ima.npy\")\n",
    "y555 = np.load(\"aug/aug4t5nummer.npy\").astype(int)\n",
    "\n",
    "y555 = hot(y555)\n",
    "x_train555, x_test555, y_train555, y_test555 = train_test_split(\n",
    "    X555, y555, test_size=0.2)\n",
    "y555 = y_train555[:,44:55]\n",
    "y555_t= y_test555[:,44:55]\n",
    "\n",
    "d5.fit(x_train555,y555,\n",
    "        batch_size=batch_size,\n",
    "        epochs=40,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d5.evaluate(x_test555, y555_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d5.save('ioncanond5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGING!!\n"
     ]
    }
   ],
   "source": [
    "print(\"MERGING!!\")\n",
    "\n",
    "# import h5py\n",
    "# f = h5py.File('ioncanond1.h5', 'r+')\n",
    "# del f['optimizer_weights']\n",
    "# f.close()\n",
    "      \n",
    "digit1 = load_model('ioncanond1.h5')\n",
    "digit1.name =\"digit1\"\n",
    "\n",
    "digit2 = load_model('ioncanond2.h5')\n",
    "digit2.name =\"digit2\"\n",
    "\n",
    "digit3 = load_model('ioncanond3.h5')\n",
    "digit3.name =\"digit3\"\n",
    "\n",
    "digit4 = load_model('ioncanond4.h5')\n",
    "digit4.name =\"digit4\"\n",
    "\n",
    "digit5 = load_model('ioncanond5.h5')\n",
    "digit5.name =\"digit5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Merging\n",
    "d1 = digit1(a)\n",
    "\n",
    "d2 = digit2(a)\n",
    "\n",
    "d3 = digit3(a)\n",
    "\n",
    "d4 = digit4(a)\n",
    "\n",
    "d5 = digit5(a)\n",
    "\n",
    "model = Model(inputs=a, outputs=[d1, d2, d3, d4, d5])\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acccc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f1310d6dfaaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macccc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acccc' is not defined"
     ]
    }
   ],
   "source": [
    "acc = acccc(model)\n",
    "print(\"Initial accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3893ec8ecd26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0macccc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ioncannonaug.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macccc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     model.fit(x_train,[y1,y2,y3,y4,y5],\n\u001b[1;32m      5\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "while(acc<=acccc(model)):\n",
    "    model.save(\"ioncannonaug.h5\")\n",
    "    acc = acccc(model)\n",
    "    model.fit(x_train,[y1,y2,y3,y4,y5],\n",
    "            batch_size=batch_size,\n",
    "            epochs=1,\n",
    "            #validation_split=0.2,\n",
    "            validation_data=(x_test,[y1_t,y2_t,y3_t,y4_t,y5_t]),\n",
    "            shuffle=True,\n",
    "            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old = load_model('ioncanondprime.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.21748241281246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.21748241281246"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acccc(old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
