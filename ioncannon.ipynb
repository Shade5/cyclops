{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from IPython.display import SVG,display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 11\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hot(y):\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(11))\n",
    "    new_y = np.zeros((y.shape[0],y.shape[1]*num_classes))\n",
    "    for i in range(len(y)):\n",
    "        new_y[i,:] = label_binarizer.transform(y[i]).flatten()\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acccc(model):\n",
    "    A = np.array(model.predict(x_test))\n",
    "    c=0\n",
    "    for i in range(A.shape[1]):\n",
    "           c+=np.array_equal(np.argmax(np.array(A[:,i,:]),axis=1)[0:5],np.argmax(y_test[i].reshape((6,11)),axis=1)[0:5])\n",
    "    print(\"Accuracy:\",100*c/A.shape[1])\n",
    "    return 100*c/A.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load(\"resizecrop.npy\")\n",
    "Y = np.load(\"nummertrain.npy\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = hot(Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (26721, 25, 23, 3)\n",
      "y_train shape: (26721, 11)\n",
      "26721 train samples\n"
     ]
    }
   ],
   "source": [
    "y1,y2,y3,y4,y5,ynum = y_train[:,0:11],y_train[:,11:22],y_train[:,22:33],y_train[:,33:44],y_train[:,44:55],y_train[:,55:66]\n",
    "y1_t,y2_t,y3_t,y4_t,y5_t,ynum_t = y_test[:,0:11],y_test[:,11:22],y_test[:,22:33],y_test[:,33:44],y_test[:,44:55],y_test[:,55:66]\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', ynum.shape)\n",
    "print(x_train.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "num = Dense(128, activation='relu')(conv_out)\n",
    "num = Dense(128, activation='relu')(num)\n",
    "num = Dropout(0.5)(num)\n",
    "numout = Dense(num_classes, activation='softmax',name=\"num\")(num)\n",
    "\n",
    "numtower = Model(inputs=inpu, outputs=numout)\n",
    "\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir='./logs/lay3', histogram_freq=0, write_graph=True, write_images=False))\n",
    "\n",
    "numtower.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26721 samples, validate on 6681 samples\n"
     ]
    }
   ],
   "source": [
    "numtower.fit(x_train, ynum,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        #validation_split=0.2,\n",
    "        validation_data=(x_test,ynum_t),\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = numtower.evaluate(x_test, ynum_t, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])\n",
    "\n",
    "numtower.save('ioncanonnum.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number tower complete\n",
      "\n",
      "starting Digit1\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Number tower complete\")\n",
    "print()\n",
    "\n",
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit1\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dropout(0.5)(x1)\n",
    "\n",
    "\n",
    "x1 = Dense(num_classes, activation='softmax', name='x2')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "callbacks.append(keras.callbacks.TensorBoard(log_dir='./logs/digit1/lay(2,2,4)', histogram_freq=0, write_graph=True, write_images=False))\n",
    "\n",
    "d1 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/workspace/venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2124: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26721 samples, validate on 6681 samples\n",
      "Epoch 1/15\n",
      "20s - loss: 2.1446 - acc: 0.2513 - val_loss: 2.0298 - val_acc: 0.2757\n",
      "Epoch 2/15\n",
      "19s - loss: 1.8559 - acc: 0.3483 - val_loss: 1.5561 - val_acc: 0.4589\n",
      "Epoch 3/15\n",
      "20s - loss: 1.3380 - acc: 0.5327 - val_loss: 1.1331 - val_acc: 0.6164\n",
      "Epoch 4/15\n",
      "19s - loss: 1.0556 - acc: 0.6441 - val_loss: 0.9824 - val_acc: 0.6870\n",
      "Epoch 5/15\n",
      "19s - loss: 0.8804 - acc: 0.7145 - val_loss: 0.6999 - val_acc: 0.7866\n",
      "Epoch 6/15\n",
      "19s - loss: 0.7595 - acc: 0.7616 - val_loss: 0.6683 - val_acc: 0.7963\n",
      "Epoch 7/15\n",
      "18s - loss: 0.6693 - acc: 0.7920 - val_loss: 0.7387 - val_acc: 0.7640\n",
      "Epoch 8/15\n",
      "19s - loss: 0.6082 - acc: 0.8121 - val_loss: 0.7477 - val_acc: 0.7601\n",
      "Epoch 9/15\n",
      "18s - loss: 0.5620 - acc: 0.8277 - val_loss: 0.5611 - val_acc: 0.8255\n",
      "Epoch 10/15\n",
      "18s - loss: 0.5115 - acc: 0.8438 - val_loss: 0.4922 - val_acc: 0.8569\n",
      "Epoch 11/15\n",
      "18s - loss: 0.4791 - acc: 0.8530 - val_loss: 0.4959 - val_acc: 0.8577\n",
      "Epoch 12/15\n",
      "18s - loss: 0.4549 - acc: 0.8596 - val_loss: 0.4668 - val_acc: 0.8680\n",
      "Epoch 13/15\n",
      "18s - loss: 0.4224 - acc: 0.8733 - val_loss: 0.4620 - val_acc: 0.8675\n",
      "Epoch 14/15\n",
      "17s - loss: 0.4001 - acc: 0.8766 - val_loss: 0.6281 - val_acc: 0.8165\n",
      "Epoch 15/15\n",
      "17s - loss: 0.3822 - acc: 0.8838 - val_loss: 0.4610 - val_acc: 0.8750\n",
      "Test loss: 0.461022071095\n",
      "Test accuracy: 0.875018709596\n"
     ]
    }
   ],
   "source": [
    "d1.fit(x_train,y1,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        #validation_split=0.2,\n",
    "        validation_data=(x_test,y1_t),\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d1.evaluate(x_test, y1_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d1.save('ioncanond1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit2\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x3')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d2 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2.fit(x_train,y2,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d2.evaluate(x_test, y2_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d2.save('ioncanond2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit3\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "\n",
    "x1 = Dropout(0.5)(x1)\n",
    "\n",
    "\n",
    "x1 = Dense(num_classes, activation='softmax', name='x1')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d3 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d3.fit(x_train,y3,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d3.evaluate(x_test, y3_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d3.save('ioncanond3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit4\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x4')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d4 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d4.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d4.fit(x_train,y4,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d4.evaluate(x_test, y4_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"part2\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=0)] \n",
    "\n",
    "X444 = np.load(\"Xcropresize4.npy\")\n",
    "y444 = np.load(\"Ycropresize4.npy\").astype(int)\n",
    "\n",
    "y444 = hot(y444)\n",
    "x_train444, x_test444, y_train444, y_test444 = train_test_split(\n",
    "    X444, y444, test_size=0.2)\n",
    "y444 = y_train444[:,33:44]\n",
    "y444_t= y_test444[:,33:44]\n",
    "\n",
    "d4.fit(x_train444,y444,\n",
    "        batch_size=batch_size,\n",
    "        epochs=50,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d4.evaluate(x_test444, y444_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d4.save('ioncanond4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numtowerfre = load_model('ioncanonnum.h5')\n",
    "numtowerfre.name =\"Numbertower\"\n",
    "print(\"starting Digit5\")\n",
    "\n",
    "inpu = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Number tower\n",
    "numtower = numtowerfre(inpu)\n",
    "numtower.trainable=False\n",
    "\n",
    "x = Conv2D(32, (2, 2), padding='same')(inpu)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (2, 2))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (4, 4), padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)\n",
    "\n",
    "x1 = keras.layers.concatenate([conv_out, numtower])\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(num_classes, activation='softmax', name='x5')(x1)\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0)]\n",
    "\n",
    "d5 = Model(inputs=inpu, outputs=x1)\n",
    "\n",
    "# display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "# load weights\n",
    "# model.load_weights(\"weights.forksvhmbest.hdf5\")\n",
    "\n",
    "d5.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'],\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d5.fit(x_train,y5,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d5.evaluate(x_test, y5_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"part2\")\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5, verbose=0)] \n",
    "\n",
    "X555 = np.load(\"Xcropresize5.npy\")\n",
    "y555 = np.load(\"Ycropresize5.npy\").astype(int)\n",
    "\n",
    "y555 = hot(y555)\n",
    "x_train555, x_test555, y_train555, y_test555 = train_test_split(\n",
    "    X555, y555, test_size=0.2)\n",
    "y555 = y_train555[:,44:55]\n",
    "y555_t= y_test555[:,44:55]\n",
    "\n",
    "d5.fit(x_train555,y555,\n",
    "        batch_size=batch_size,\n",
    "        epochs=50,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "score = d5.evaluate(x_test555, y555_t, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "d5.save('ioncanond5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERGING!!\n"
     ]
    }
   ],
   "source": [
    "print(\"MERGING!!\")\n",
    "\n",
    "# import h5py\n",
    "# f = h5py.File('ioncanond1.h5', 'r+')\n",
    "# del f['optimizer_weights']\n",
    "# f.close()\n",
    "      \n",
    "digit1 = load_model('ioncanond1.h5')\n",
    "digit1.name =\"digit1\"\n",
    "\n",
    "digit2 = load_model('ioncanond2.h5')\n",
    "digit2.name =\"digit2\"\n",
    "\n",
    "digit3 = load_model('ioncanond3.h5')\n",
    "digit3.name =\"digit3\"\n",
    "\n",
    "digit4 = load_model('ioncanond4.h5')\n",
    "digit4.name =\"digit4\"\n",
    "\n",
    "digit5 = load_model('ioncanond5.h5')\n",
    "digit5.name =\"digit5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Merging\n",
    "d1 = digit1(a)\n",
    "\n",
    "d2 = digit2(a)\n",
    "\n",
    "d3 = digit3(a)\n",
    "\n",
    "d4 = digit4(a)\n",
    "\n",
    "d5 = digit5(a)\n",
    "\n",
    "model = Model(inputs=a, outputs=[d1, d2, d3, d4, d5])\n",
    "\n",
    "#display(SVG(model_to_dot(model).create(prog='dot', format='svg')))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.21239335428828\n",
      "Initial accuracy:  1.21239335428828\n"
     ]
    }
   ],
   "source": [
    "acc = acccc(model)\n",
    "print(\"Initial accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.21239335428828\n",
      "Accuracy: 1.21239335428828\n",
      "Train on 26721 samples, validate on 6681 samples\n",
      "Epoch 1/1\n",
      "90s - loss: 1.2518 - digit1_loss: 0.3119 - digit2_loss: 0.4974 - digit3_loss: 0.3154 - digit4_loss: 0.1225 - digit5_loss: 0.0046 - digit1_acc: 0.9115 - digit2_acc: 0.8562 - digit3_acc: 0.9136 - digit4_acc: 0.9716 - digit5_acc: 0.9996 - val_loss: 1.3869 - val_digit1_loss: 0.4410 - val_digit2_loss: 0.5600 - val_digit3_loss: 0.2854 - val_digit4_loss: 0.0908 - val_digit5_loss: 0.0097 - val_digit1_acc: 0.8648 - val_digit2_acc: 0.8352 - val_digit3_acc: 0.9147 - val_digit4_acc: 0.9781 - val_digit5_acc: 0.9994\n",
      "Accuracy: 69.64526268522677\n",
      "Accuracy: 69.64526268522677\n",
      "Train on 26721 samples, validate on 6681 samples\n",
      "Epoch 1/1\n",
      "88s - loss: 0.9924 - digit1_loss: 0.2517 - digit2_loss: 0.4150 - digit3_loss: 0.2435 - digit4_loss: 0.0786 - digit5_loss: 0.0036 - digit1_acc: 0.9284 - digit2_acc: 0.8783 - digit3_acc: 0.9305 - digit4_acc: 0.9803 - digit5_acc: 0.9998 - val_loss: 1.4512 - val_digit1_loss: 0.2727 - val_digit2_loss: 0.8252 - val_digit3_loss: 0.2546 - val_digit4_loss: 0.0891 - val_digit5_loss: 0.0097 - val_digit1_acc: 0.9183 - val_digit2_acc: 0.7469 - val_digit3_acc: 0.9300 - val_digit4_acc: 0.9789 - val_digit5_acc: 0.9994\n",
      "Accuracy: 66.93608741206407\n"
     ]
    }
   ],
   "source": [
    "while(acc<=acccc(model)):\n",
    "    model.save(\"ioncannongalactus.h5\")\n",
    "    acc = acccc(model)\n",
    "    model.fit(x_train,[y1,y2,y3,y4,y5],\n",
    "            batch_size=batch_size,\n",
    "            epochs=1,\n",
    "            #validation_split=0.2,\n",
    "            validation_data=(x_test,[y1_t,y2_t,y3_t,y4_t,y5_t]),\n",
    "            shuffle=True,\n",
    "            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old = load_model('ioncanondprime.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.21748241281246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.21748241281246"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acccc(old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
